{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.17","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"tpu1vmV38","dataSources":[{"sourceId":11980919,"sourceType":"datasetVersion","datasetId":7534899},{"sourceId":11992835,"sourceType":"datasetVersion","datasetId":7543335}],"dockerImageVersionId":31041,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":false}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"!pip install -q torch torchvision h5py huggingface_hub tqdm","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true,"execution":{"iopub.status.busy":"2025-06-03T03:12:46.284679Z","iopub.execute_input":"2025-06-03T03:12:46.285043Z","iopub.status.idle":"2025-06-03T03:12:51.447672Z","shell.execute_reply.started":"2025-06-03T03:12:46.285017Z","shell.execute_reply":"2025-06-03T03:12:51.441867Z"}},"outputs":[{"name":"stdout","text":"\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n\u001b[0m\n\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m23.0.1\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m25.1.1\u001b[0m\n\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpip install --upgrade pip\u001b[0m\n","output_type":"stream"}],"execution_count":3},{"cell_type":"code","source":"!pip install -q torchmetrics","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-06-03T03:14:52.058132Z","iopub.execute_input":"2025-06-03T03:14:52.058478Z","iopub.status.idle":"2025-06-03T03:14:56.935273Z","shell.execute_reply.started":"2025-06-03T03:14:52.058451Z","shell.execute_reply":"2025-06-03T03:14:56.930904Z"}},"outputs":[{"name":"stdout","text":"\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n\u001b[0m\n\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m23.0.1\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m25.1.1\u001b[0m\n\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpip install --upgrade pip\u001b[0m\n","output_type":"stream"}],"execution_count":8},{"cell_type":"code","source":"!pip install -U albumentations","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-06-03T03:12:51.449949Z","iopub.execute_input":"2025-06-03T03:12:51.450230Z","iopub.status.idle":"2025-06-03T03:12:55.770852Z","shell.execute_reply.started":"2025-06-03T03:12:51.450199Z","shell.execute_reply":"2025-06-03T03:12:55.765588Z"}},"outputs":[{"name":"stdout","text":"Requirement already satisfied: albumentations in /usr/local/lib/python3.10/site-packages (2.0.6)\nCollecting albumentations\n  Downloading albumentations-2.0.8-py3-none-any.whl (369 kB)\n\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m369.4/369.4 kB\u001b[0m \u001b[31m6.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n\u001b[?25hRequirement already satisfied: albucore==0.0.24 in /usr/local/lib/python3.10/site-packages (from albumentations) (0.0.24)\nRequirement already satisfied: numpy>=1.24.4 in /usr/local/lib/python3.10/site-packages (from albumentations) (2.0.2)\nRequirement already satisfied: pydantic>=2.9.2 in /usr/local/lib/python3.10/site-packages (from albumentations) (2.11.4)\nRequirement already satisfied: PyYAML in /usr/local/lib/python3.10/site-packages (from albumentations) (6.0.2)\nRequirement already satisfied: scipy>=1.10.0 in /usr/local/lib/python3.10/site-packages (from albumentations) (1.15.2)\nRequirement already satisfied: opencv-python-headless>=4.9.0.80 in /usr/local/lib/python3.10/site-packages (from albumentations) (4.11.0.86)\nRequirement already satisfied: stringzilla>=3.10.4 in /usr/local/lib/python3.10/site-packages (from albucore==0.0.24->albumentations) (3.12.5)\nRequirement already satisfied: simsimd>=5.9.2 in /usr/local/lib/python3.10/site-packages (from albucore==0.0.24->albumentations) (6.2.1)\nRequirement already satisfied: typing-extensions>=4.12.2 in /usr/local/lib/python3.10/site-packages (from pydantic>=2.9.2->albumentations) (4.13.2)\nRequirement already satisfied: typing-inspection>=0.4.0 in /usr/local/lib/python3.10/site-packages (from pydantic>=2.9.2->albumentations) (0.4.0)\nRequirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.10/site-packages (from pydantic>=2.9.2->albumentations) (0.7.0)\nRequirement already satisfied: pydantic-core==2.33.2 in /usr/local/lib/python3.10/site-packages (from pydantic>=2.9.2->albumentations) (2.33.2)\nInstalling collected packages: albumentations\n  Attempting uninstall: albumentations\n    Found existing installation: albumentations 2.0.6\n    Uninstalling albumentations-2.0.6:\n      Successfully uninstalled albumentations-2.0.6\nSuccessfully installed albumentations-2.0.8\n\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n\u001b[0m\n\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m23.0.1\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m25.1.1\u001b[0m\n\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpip install --upgrade pip\u001b[0m\n","output_type":"stream"}],"execution_count":4},{"cell_type":"code","source":"# Thư viện\nimport os\nimport sys\nimport h5py\nimport numpy as np\nimport torch\nfrom torch.utils.data import Dataset, DataLoader, random_split, WeightedRandomSampler\nfrom torchvision import transforms, models\nfrom torch.cuda.amp import GradScaler, autocast\nfrom torchmetrics.classification import MulticlassAccuracy\nimport timm\nimport albumentations as A\nfrom albumentations.pytorch import ToTensorV2\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nfrom sklearn.metrics import classification_report, confusion_matrix\n# Đường dẫn\nINPUT_DIR = \"/kaggle/input/galaxy10-decals\"         # thay bằng tên dataset của bạn\nH5_PATH   = f\"{INPUT_DIR}/Galaxy10_DECals.h5\"\nSAVE_PATH = \"/kaggle/working/galaxy10_b0.pth\"       # checkpoint & đồ thị sẽ lưu ở đây\nassert os.path.exists(H5_PATH), f\"❌ Không tìm thấy file HDF5: {H5_PATH}\"\nprint(\"✅ Đã tìm thấy:\", H5_PATH)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-06-03T03:14:57.654573Z","iopub.execute_input":"2025-06-03T03:14:57.654867Z","iopub.status.idle":"2025-06-03T03:15:11.683290Z","shell.execute_reply.started":"2025-06-03T03:14:57.654839Z","shell.execute_reply":"2025-06-03T03:15:11.677053Z"}},"outputs":[{"name":"stderr","text":"/usr/local/lib/python3.10/site-packages/torch_xla/__init__.py:251: UserWarning: `tensorflow` can conflict with `torch-xla`. Prefer `tensorflow-cpu` when using PyTorch/XLA. To silence this warning, `pip uninstall -y tensorflow && pip install tensorflow-cpu`. If you are in a notebook environment such as Colab or Kaggle, restart your notebook runtime afterwards.\n  warnings.warn(\n","output_type":"stream"},{"name":"stdout","text":"✅ Đã tìm thấy: /kaggle/input/galaxy10-decals/Galaxy10_DECals.h5\n","output_type":"stream"}],"execution_count":9},{"cell_type":"code","source":"import albumentations as A\nfrom albumentations.pytorch import ToTensorV2\nimport torchvision.transforms as T\nIMG_SIZE = 224\nMEAN, STD = [0.485, 0.456, 0.406], [0.229, 0.224, 0.225]\n# Albumentations chịu trách nhiệm về resize/augmentation chính:\nalb_train = A.Compose([\n    A.RandomResizedCrop(size=(IMG_SIZE, IMG_SIZE), scale=(0.8, 1.0), ratio=(0.75, 1.333)),\n    A.HorizontalFlip(p=0.5),\n    A.Rotate(limit=180, p=0.5),\n    A.RandomBrightnessContrast(p=0.3),\n    A.GaussianBlur(p=0.2),\n    A.Normalize(MEAN, STD),\n    ToTensorV2(),   # kết quả trả về là Tensor (C, H, W)\n])\nalb_val = A.Compose([\n    A.Resize(height=IMG_SIZE, width=IMG_SIZE),\n    A.Normalize(MEAN, STD),\n    ToTensorV2(),\n])\ntorch_train_extra = T.RandomErasing(\n    p=0.3,\n    scale=(0.02, 0.2),\n    ratio=(0.3, 3.3),\n    value=0\n)\ntorch_val_extra = T.Lambda(lambda x: x)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-06-03T03:15:11.684094Z","iopub.execute_input":"2025-06-03T03:15:11.684499Z","iopub.status.idle":"2025-06-03T03:15:11.704843Z","shell.execute_reply.started":"2025-06-03T03:15:11.684475Z","shell.execute_reply":"2025-06-03T03:15:11.699320Z"}},"outputs":[],"execution_count":10},{"cell_type":"code","source":"# Dataset \nclass Galaxy10H5(Dataset):\n    def __init__(self, h5_path, indices=None, transform=None, extra_tfm=None):\n        self.h5 = h5py.File(h5_path, \"r\")\n        self.imgs = self.h5[\"images\"]\n        self.labs = self.h5[\"ans\"]\n        self.idxs = np.arange(len(self.imgs)) if indices is None else indices\n        self.transform = transform\n        self.extra = extra_tfm\n    def __len__(self):\n        return len(self.idxs)\n    def __getitem__(self, i):\n        # Lấy ảnh + label tại vị trí self.idxs[i]\n        img = self.imgs[self.idxs[i]]           # numpy array (256, 256, 3) uint8\n        lab = int(self.labs[self.idxs[i]])      # label (0–9)\n        if self.transform is not None:\n            # Albumentations: input là np.ndarray, output là dict {'image': tensor}\n            img = self.transform(image=img)[\"image\"]  # bây giờ img là Tensor (C, H, W)\n        if self.extra is not None:\n            img = self.extra(img)  # extra nhận Tensor, trả Tensor\n        return img, lab","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-06-03T03:15:15.725895Z","iopub.execute_input":"2025-06-03T03:15:15.726251Z","iopub.status.idle":"2025-06-03T03:15:15.739056Z","shell.execute_reply.started":"2025-06-03T03:15:15.726222Z","shell.execute_reply":"2025-06-03T03:15:15.734514Z"}},"outputs":[],"execution_count":11},{"cell_type":"code","source":"from torch.utils.data import random_split, WeightedRandomSampler, DataLoader\nimport os\n# Tạo dataset gốc KHÔNG transform (chỉ để random_split)\nfull_ds_base = Galaxy10H5(H5_PATH, transform=None, extra_tfm=None)\n# Lấy kích thước và tách chỉ số: 80% train, 10% val, 10% test\nN = len(full_ds_base)\nn_val  = int(0.10 * N)\nn_test = int(0.10 * N)\nn_train = N - n_val - n_test\ng = torch.Generator().manual_seed(42)\n# Kết quả của random_split là 3 object Subset, mỗi Subset giữ .indices\ntrain_subset, val_subset, test_subset = random_split(full_ds_base, [n_train, n_val, n_test], generator=g)\ntrain_idxs = train_subset.indices\nval_idxs   = val_subset.indices\ntest_idxs  = test_subset.indices\n# Tạo dataset riêng cho train/val/test, gán transform/extra_tfm tương ứng\ntrain_ds = Galaxy10H5(\n    H5_PATH,\n    indices=train_idxs,\n    transform=alb_train,       # Albumentations cho train\n    extra_tfm=torch_train_extra  # RandomErasing chỉ dùng trên train\n)\nval_ds = Galaxy10H5(\n    H5_PATH,\n    indices=val_idxs,\n    transform=alb_val,         # Albumentations cho validation\n    extra_tfm=torch_val_extra  # torch_val_extra = lambda x: x (không làm gì)\n)\ntest_ds = Galaxy10H5(\n    H5_PATH,\n    indices=test_idxs,\n    transform=alb_val,         # Xài đúng val transform (không augmentation ngẫu nhiên)\n    extra_tfm=torch_val_extra\n)\n# Tạo WeightedRandomSampler cho train (cân bằng lớp)\ntargets = np.array([full_ds_base.labs[i] for i in train_idxs])\nclass_counts = np.bincount(targets, minlength=10)   # 10 classes\nclass_weights = 1.0 / class_counts\nsample_weights = class_weights[targets]\nsampler = WeightedRandomSampler(sample_weights, len(sample_weights), replacement=True)\nBATCH = 64\nNUM_WORKERS = min(8, os.cpu_count())\n# DataLoader\ntrain_loader = DataLoader(\n    train_ds,\n    batch_size=BATCH,\n    sampler=sampler,       # dùng sampler để cân bằng\n    num_workers=NUM_WORKERS,\n    pin_memory=True\n)\nval_loader = DataLoader(\n    val_ds,\n    batch_size=BATCH,\n    shuffle=False,\n    num_workers=NUM_WORKERS,\n    pin_memory=True\n)\ntest_loader = DataLoader(\n    test_ds,\n    batch_size=BATCH,\n    shuffle=False,\n    num_workers=NUM_WORKERS,\n    pin_memory=True\n)\nprint(f\"Train {len(train_ds)} | Val {len(val_ds)} | Test {len(test_ds)}\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-06-03T03:15:17.383284Z","iopub.execute_input":"2025-06-03T03:15:17.383616Z","iopub.status.idle":"2025-06-03T03:15:17.483808Z","shell.execute_reply.started":"2025-06-03T03:15:17.383586Z","shell.execute_reply":"2025-06-03T03:15:17.479137Z"}},"outputs":[{"name":"stdout","text":"Train 14190 | Val 1773 | Test 1773\n","output_type":"stream"}],"execution_count":12},{"cell_type":"code","source":"device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\nNUM_CLASSES = 10\nmodel = timm.create_model(\"efficientnet_b2\", pretrained=True, num_classes=NUM_CLASSES)\nmodel = model.to(device)\n# Focal Loss (xử lý imbalance)\nclass FocalLoss(torch.nn.Module):\n    def __init__(self, gamma=2.0):\n        super().__init__()\n        self.gamma = gamma\n    def forward(self, logits, targets):\n        ce = torch.nn.functional.cross_entropy(logits, targets, reduction=\"none\")\n        p_t = torch.exp(-ce)\n        loss = ((1 - p_t) ** self.gamma * ce).mean()\n        return loss\ncriterion = FocalLoss(gamma=2.0)\noptimizer = torch.optim.AdamW(model.parameters(), lr=3e-4, weight_decay=1e-4)\n# OneCycleLR: max_lr=3e-3, epochs=20, steps_per_epoch=len(train_loader)\nscheduler = torch.optim.lr_scheduler.OneCycleLR(\n    optimizer,\n    max_lr=3e-3,\n    steps_per_epoch=len(train_loader),\n    epochs=10\n)\nscaler = GradScaler()\nmetric = MulticlassAccuracy(num_classes=NUM_CLASSES).to(device)\nSAVE_PATH = \"galaxy10_ema.pth\"","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-06-03T03:15:20.280432Z","iopub.execute_input":"2025-06-03T03:15:20.280807Z","iopub.status.idle":"2025-06-03T03:15:20.946009Z","shell.execute_reply.started":"2025-06-03T03:15:20.280770Z","shell.execute_reply":"2025-06-03T03:15:20.939144Z"}},"outputs":[{"name":"stderr","text":"/tmp/ipykernel_10/551400850.py:24: FutureWarning: `torch.cuda.amp.GradScaler(args...)` is deprecated. Please use `torch.amp.GradScaler('cuda', args...)` instead.\n  scaler = GradScaler()\n","output_type":"stream"}],"execution_count":13},{"cell_type":"code","source":"from copy import deepcopy\nfrom tqdm.auto import tqdm         \nimport torch\nbest_val_acc = 0.0\npatience_cnt = 0\nEPOCHS, PATIENCE = 10, 5         \nema_state = deepcopy(model.state_dict())\nhistory = {\n    \"train_loss\": [], \n    \"val_loss\": [], \n    \"train_acc\": [], \n    \"val_acc\": []\n}\ndef run_epoch(loader, train=True):\n    if train:\n        model.train()\n    else:\n        model.eval()\n    torch.set_grad_enabled(train)\n    total_loss = 0.0\n    total_samples = 0\n    metric.reset()\n    loop = tqdm(loader, leave=False)\n    for x, y in loop:\n        # Chuyển data lên device (cuda hoặc cpu)\n        x, y = x.to(device), y.to(device)\n        if train:\n            optimizer.zero_grad()   # reset gradients chỉ khi train\n        # Mixed precision: autocast cho forward + loss\n        with torch.cuda.amp.autocast():\n            logits = model(x)             # output shape: (B, NUM_CLASSES)\n            loss = criterion(logits, y)   # FocalLoss hoặc CrossEntropy, v.v.\n        if train:\n            scaler.scale(loss).backward()  # scale loss rồi backward\n            scaler.step(optimizer)\n            scaler.update()\n            scheduler.step()              # OneCycleLR điều chỉnh lr sau mỗi batch\n        # Cộng dồn tổng loss, tính số samples\n        batch_size = x.size(0)\n        total_loss += loss.item() * batch_size\n        total_samples += batch_size\n        # Cập nhật accuracy metric (dùng logits.softmax vì MulticlassAccuracy cần probs)\n        with torch.no_grad():\n            probs = logits.softmax(dim=1)\n            metric.update(probs, y)\n        # Hiển thị progress bar, show loss hiện tại\n        loop.set_postfix(batch_loss=loss.item())\n    # Kết thúc loop, tính loss trung bình và acc trung bình\n    avg_loss = total_loss / total_samples\n    avg_acc  = metric.compute().item()\n    return avg_loss, avg_acc\nfor epoch in range(1, EPOCHS + 1):\n    # Chạy 1 epoch train\n    tr_loss, tr_acc = run_epoch(train_loader, train=True)\n    # Chạy 1 epoch validation (train=False tự động tắt gradient)\n    val_loss, val_acc = run_epoch(val_loader, train=False)\n    # Lưu lại lịch sử để plot learning curves sau\n    history[\"train_loss\"].append(tr_loss)\n    history[\"val_loss\"].append(val_loss)\n    history[\"train_acc\"].append(tr_acc)\n    history[\"val_acc\"].append(val_acc)\n    # In ra màn hình tiến độ epoch\n    # In ra learning rate hiện tại (lấy từ optimizer)\n    current_lr = optimizer.param_groups[0][\"lr\"]\n    print(\n        f\"Epoch {epoch:02d} | \"\n        f\"Train Loss: {tr_loss:.4f}, Train Acc: {tr_acc:.3%} | \"\n        f\"Val   Loss: {val_loss:.4f}, Val   Acc: {val_acc:.3%} | \"\n        f\"LR: {current_lr:.2e}\"\n    )\n    # Cập nhật EMA (alpha = 0.999)\n    for key in ema_state:\n        ema_state[key] = 0.999 * ema_state[key] + 0.001 * model.state_dict()[key]\n    # Nếu validation accuracy được cải thiện thì reset patience, lưu checkpoint EMA\n    if val_acc > best_val_acc:\n        best_val_acc = val_acc\n        patience_cnt = 0\n        torch.save({\"model\": ema_state, \"acc\": best_val_acc}, SAVE_PATH)\n        print(\"Save new best EMA model\")\n    else:\n        patience_cnt += 1\n        if patience_cnt >= PATIENCE:\n            print(\"Early stopping triggered\")\n            break\nprint(f\"\\nFinished training. Best Validation Acc: {best_val_acc:.3%}\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-06-03T03:15:25.744457Z","iopub.execute_input":"2025-06-03T03:15:25.744768Z"}},"outputs":[{"name":"stderr","text":"  0%|          | 0/222 [00:00<?, ?it/s]","output_type":"stream"}],"execution_count":null},{"cell_type":"code","source":"ckpt = torch.load(SAVE_PATH, map_location=device)\nmodel.load_state_dict(ckpt[\"model\"])\nmodel.eval()\nall_preds = []\nall_labels = []\nwith torch.no_grad(), autocast():\n    for x, y in tqdm(test_loader, leave=False):\n        x, y = x.to(device), y.to(device)\n        logits = model(x)\n        preds = logits.argmax(dim=1).cpu().numpy()\n        labels = y.cpu().numpy()\n        all_preds.append(preds)\n        all_labels.append(labels)\nall_preds = np.concatenate(all_preds)\nall_labels = np.concatenate(all_labels)\nprint(\"Test accuracy:\", (all_preds == all_labels).mean() * 100, \"%\")\nprint(classification_report(all_labels, all_preds, target_names=[f\"class_{i}\" for i in range(NUM_CLASSES)]))\n# Vẽ confusion matrix\ncm = confusion_matrix(all_labels, all_preds, normalize=\"true\")\nplt.figure(figsize=(6,5))\nsns.heatmap(cm, annot=True, fmt=\".2f\", cmap=\"Blues\",\n            xticklabels=[f\"c{i}\" for i in range(NUM_CLASSES)],\n            yticklabels=[f\"c{i}\" for i in range(NUM_CLASSES)])\nplt.xlabel(\"Predicted\")\nplt.ylabel(\"True\")\nplt.title(\"Confusion Matrix\")\nplt.show()","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# Vẽ Learning Curve\n# Sau khi training kết thúc (hoặc early-stopped), history chứa list loss/acc từng epoch\nepochs = range(1, len(history[\"train_loss\"]) + 1)\nplt.figure(figsize=(12, 5))\n# Plot loss\nplt.subplot(1, 2, 1)\nplt.plot(epochs, history[\"train_loss\"], label=\"Train Loss\")\nplt.plot(epochs, history[\"val_loss\"],   label=\"Val Loss\")\nplt.xlabel(\"Epoch\")\nplt.ylabel(\"Loss\")\nplt.legend()\nplt.title(\"Training and Validation Loss\")\n# Plot accuracy\nplt.subplot(1, 2, 2)\nplt.plot(epochs, history[\"train_acc\"], label=\"Train Acc\")\nplt.plot(epochs, history[\"val_acc\"],   label=\"Val Acc\")\nplt.xlabel(\"Epoch\")\nplt.ylabel(\"Accuracy\")\nplt.legend()\nplt.title(\"Training and Validation Accuracy\")\nplt.tight_layout()\nplt.show()","metadata":{"trusted":true},"outputs":[],"execution_count":null}]}